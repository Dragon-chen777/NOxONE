;(window.webpackJsonp = window.webpackJsonp || []).push([
	[28],
	{
		461: function (t, s, a) {
			'use strict'
			a.r(s)
			var n = a(1),
				e = Object(n.a)(
					{},
					function () {
						var t = this,
							s = t._self._c
						return s('ContentSlotsDistributor', { attrs: { 'slot-key': t.$parent.slotKey } }, [
							s('h2', { attrs: { id: '_1-set' } }, [s('a', { staticClass: 'header-anchor', attrs: { href: '#_1-set' } }, [t._v('#')]), t._v(' 1. Set')]),
							t._v(' '),
							s('p', [
								s('code', [t._v('Set')]),
								t._v('是 ES6 新增的'),
								s('code', [t._v('引用数据类型')]),
								t._v('，类似于数组，但是项（对于对象来说是'),
								s('code', [t._v('指针')]),
								t._v('喔~）都是'),
								s('code', [t._v('唯一')]),
								t._v('的，可用于'),
								s('code', [t._v('数组去重')]),
							]),
							t._v(' '),
							s('div', { staticClass: 'language-js extra-class' }, [
								s('pre', { pre: !0, attrs: { class: 'language-js' } }, [
									s('code', [
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('new')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token class-name' } }, [t._v('Set')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('[')]),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('1')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('2')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('3')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('2')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(']')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\n\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// 结构如下')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Set')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token parameter' } }, [s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('3')])]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										t._v('\n  '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('[')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('[')]),
										t._v('Entries'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(']')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(']')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										s('span', { pre: !0, attrs: { class: 'token string-property property' } }, [t._v("'0'")]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('1')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string-property property' } }, [t._v("'1'")]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('2')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string-property property' } }, [t._v("'2'")]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('3')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v('\n  '),
										s('span', { pre: !0, attrs: { class: 'token literal-property property' } }, [t._v('size')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('3')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										t._v('\n'),
									]),
								]),
							]),
							s('h2', { attrs: { id: '_1-属性' } }, [s('a', { staticClass: 'header-anchor', attrs: { href: '#_1-属性' } }, [t._v('#')]), t._v(' 1. 属性')]),
							t._v(' '),
							s('p', [s('code', [t._v('size')]), t._v(': 返回 Set 实例的项数')]),
							t._v(' '),
							s('h2', { attrs: { id: '_2-方法' } }, [s('a', { staticClass: 'header-anchor', attrs: { href: '#_2-方法' } }, [t._v('#')]), t._v(' 2. 方法')]),
							t._v(' '),
							s('div', { staticClass: 'language-js extra-class' }, [
								s('pre', { pre: !0, attrs: { class: 'language-js' } }, [
									s('code', [
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('add')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										t._v('item'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' 向Set添加某项，并返回自身（意味可以链式调用）\n'),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('delete')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										t._v('item'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' 删除某项，返回boolean表示是否删除成功\n'),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('has')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										t._v('item'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' 检查是否含有某项，返回boolean\n'),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('clear')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' 清除所有项\n'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('[')]),
										t._v('Symbol'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										t._v('iterator'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(']')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' Set类型预置了迭代器，可以进行迭代操作'),
										s('span', { pre: !0, attrs: { class: 'token template-string' } }, [
											s('span', { pre: !0, attrs: { class: 'token template-punctuation string' } }, [t._v('`')]),
											s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('for...of')]),
											s('span', { pre: !0, attrs: { class: 'token template-punctuation string' } }, [t._v('`')]),
										]),
										t._v('、'),
										s('span', { pre: !0, attrs: { class: 'token template-string' } }, [
											s('span', { pre: !0, attrs: { class: 'token template-punctuation string' } }, [t._v('`')]),
											s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('...')]),
											s('span', { pre: !0, attrs: { class: 'token template-punctuation string' } }, [t._v('`')]),
										]),
										t._v('\n'),
									]),
								]),
							]),
							s('p', [t._v('示例如下:')]),
							t._v(' '),
							s('div', { staticClass: 'language-js extra-class' }, [
								s('pre', { pre: !0, attrs: { class: 'language-js' } }, [
									s('code', [
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('let')]),
										t._v(' s '),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('=')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('new')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token class-name' } }, [t._v('Set')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('[')]),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('1')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('2')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(']')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('add')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('3')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('add')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('4')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// [1,2,3,4]')]),
										t._v('\ns'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('add')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('5')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// [1,2,3,4,5]')]),
										t._v('\ns'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('delete')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('5')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// true,删除成功:[1,2,3,4]')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('for')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('let')]),
										t._v(' item '),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('of')]),
										t._v(' s'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('alert')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										t._v('item'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// 1,2,3,4')]),
										t._v('\ns'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('has')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('1')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// true')]),
										t._v('\ns'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('clear')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// s.size === 0, true')]),
										t._v('\n'),
									]),
								]),
							]),
							s('p', [t._v('遍历操作')]),
							t._v(' '),
							s('div', { staticClass: 'language-js extra-class' }, [
								s('pre', { pre: !0, attrs: { class: 'language-js' } }, [
									s('code', [
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('for')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('...')]),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('of')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' 遍历集合每一项\n'),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('keys')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' 返回键名数组\n'),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('values')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' 返回键值数组\n'),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('entries')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' 返回键值对数组\n'),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('forEach')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token parameter' } }, [t._v('item')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('=>')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('...')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' 使用回调函数遍历每一项\n\n'),
									]),
								]),
							]),
							s('p', [t._v('示例如下')]),
							t._v(' '),
							s('div', { staticClass: 'language-js extra-class' }, [
								s('pre', { pre: !0, attrs: { class: 'language-js' } }, [
									s('code', [
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('const')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										t._v(' log '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('=')]),
										t._v(' console\n\n'),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('const')]),
										t._v(' s '),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('=')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('new')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token class-name' } }, [t._v('Set')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('[')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('1')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('2')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('2')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('3')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(']')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('forEach')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token parameter' } }, [t._v('item')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('=>')]),
										t._v(' s'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('add')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										t._v('item'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// Set(3){1,2,3} 唯一性')]),
										t._v('\n\n'),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('for')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('let')]),
										t._v(' item '),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('of')]),
										t._v(' s'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('log')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										t._v('item'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// 1,2,3')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('for')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('let')]),
										t._v(' key '),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('of')]),
										t._v(' s'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('keys')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('log')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										t._v('key'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// 1,2,3')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('for')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('let')]),
										t._v(' val '),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('of')]),
										t._v(' s'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('values')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('log')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										t._v('val'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// 1,2,3')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('for')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('let')]),
										t._v(' entry '),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('of')]),
										t._v(' s'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('entries')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('log')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										t._v('entry'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// [1,1],[2,2],[3,3]')]),
										t._v('\ns'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('forEach')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token parameter' } }, [t._v('item')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('=>')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('log')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										t._v('item'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// 1,2,3')]),
										t._v('\n'),
									]),
								]),
							]),
							s('h2', { attrs: { id: '_3-set-函数可以接收iterable作为初始化参数' } }, [
								s('a', { staticClass: 'header-anchor', attrs: { href: '#_3-set-函数可以接收iterable作为初始化参数' } }, [t._v('#')]),
								t._v(' 3. Set 函数可以接收'),
								s('code', [t._v('iterable')]),
								t._v('作为初始化参数'),
							]),
							t._v(' '),
							s('div', { staticClass: 'language-js extra-class' }, [
								s('pre', { pre: !0, attrs: { class: 'language-js' } }, [
									s('code', [
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('const')]),
										t._v(' set '),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('=')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('new')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token class-name' } }, [t._v('Set')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('[')]),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('1')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('2')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('2')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('3')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(']')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\n\n'),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('const')]),
										t._v(' set1 '),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('=')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('new')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token class-name' } }, [t._v('Set')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										t._v('document'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('querySelectorAll')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v("'div'")]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// 等价于')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('const')]),
										t._v(' set1 '),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('=')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('new')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token class-name' } }, [t._v('Set')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('let')]),
										t._v(' divs '),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('=')]),
										t._v(' document'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('querySelectorAll')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v("'div'")]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('for')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('let')]),
										t._v(' item '),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('of')]),
										t._v(' divs'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v(' set1'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('add')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										t._v('item'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\n'),
									]),
								]),
							]),
							s('p', [t._v('用 set 来实现'), s('code', [t._v('数组去重')]), t._v('和'), s('code', [t._v('字符串去重')])]),
							t._v(' '),
							s('div', { staticClass: 'language-js extra-class' }, [
								s('pre', { pre: !0, attrs: { class: 'language-js' } }, [
									s('code', [
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('[')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('...')]),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('new')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token class-name' } }, [t._v('Set')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('[')]),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('1')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('2')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('2')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('3')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(']')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(']')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('[')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('...')]),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('new')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token class-name' } }, [t._v('Set')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v("'abbc'")]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(']')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('join')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v("''")]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\n'),
									]),
								]),
							]),
							s('h2', { attrs: { id: '☆4-set-实现交集、并集、差集' } }, [
								s('a', { staticClass: 'header-anchor', attrs: { href: '#☆4-set-实现交集、并集、差集' } }, [t._v('#')]),
								t._v(' ☆4. Set 实现交集、并集、差集'),
							]),
							t._v(' '),
							s('div', { staticClass: 'language-js extra-class' }, [
								s('pre', { pre: !0, attrs: { class: 'language-js' } }, [
									s('code', [
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('let')]),
										t._v(' arr1 '),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('=')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('[')]),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('1')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('1')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('2')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('3')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(']')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('let')]),
										t._v(' arr2 '),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('=')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('[')]),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('2')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('3')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('4')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(']')]),
										t._v('\n\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// 并集')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('function')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('union')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token parameter' } }, [t._v('arr1'), s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]), t._v(' arr2')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										t._v('\n\t'),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('return')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('[')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('...')]),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('new')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token class-name' } }, [t._v('Set')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('[')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('...')]),
										t._v('arr1'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('...')]),
										t._v('arr2'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(']')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(']')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// 交集')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('function')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('intersect')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token parameter' } }, [t._v('arr1'), s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]), t._v(' arr2')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										t._v('\n\t'),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('return')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('[')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('...')]),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('new')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token class-name' } }, [t._v('Set')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										t._v('arr1'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(']')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('filter')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token parameter' } }, [t._v('item')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('=>')]),
										t._v(' arr2'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('includes')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										t._v('item'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// 差集')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('function')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('difference')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token parameter' } }, [t._v('arr1'), s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]), t._v(' arr2')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										t._v('\n\t'),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('return')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('[')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('...')]),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('new')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token class-name' } }, [t._v('Set')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										t._v('arr1'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(']')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('filter')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token parameter' } }, [t._v('item')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('=>')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('!')]),
										t._v('arr2'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('includes')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										t._v('item'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										t._v('\n'),
									]),
								]),
							]),
						])
					},
					[],
					!1,
					null,
					null,
					null,
				)
			s.default = e.exports
		},
	},
])
