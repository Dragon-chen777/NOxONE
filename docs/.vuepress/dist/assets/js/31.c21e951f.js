;(window.webpackJsonp = window.webpackJsonp || []).push([
	[31],
	{
		468: function (t, s, a) {
			'use strict'
			a.r(s)
			var n = a(1),
				e = Object(n.a)(
					{},
					function () {
						var t = this,
							s = t._self._c
						return s('ContentSlotsDistributor', { attrs: { 'slot-key': t.$parent.slotKey } }, [
							s('h2', { attrs: { id: '_1-连接数据库' } }, [s('a', { staticClass: 'header-anchor', attrs: { href: '#_1-连接数据库' } }, [t._v('#')]), t._v(' 1. 连接数据库')]),
							t._v(' '),
							s('div', { staticClass: 'language-js extra-class' }, [
								s('pre', { pre: !0, attrs: { class: 'language-js' } }, [
									s('code', [
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// [username[:password]@][protocol[(address)]]/dbname[?param1=value1&...&paramN=valueN] ')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// data source name, 详情参考：https://github.com/go-sql-driver/mysql#dsn-data-source-name  ')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token literal-property property' } }, [t._v('dsn')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('=')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"root:123456@tcp(127.0.0.1:3306)/gormLearn?charset=utf8mb4&parseTime=True&loc=Local"')]),
										t._v(' \ndb'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token literal-property property' } }, [t._v('_')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('=')]),
										t._v(' gorm'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Open')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										t._v('mysql'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Open')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										t._v('dsn'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('gorm'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										t._v('Config'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\n'),
									]),
								]),
							]),
							s('h2', { attrs: { id: '_2-创建表' } }, [s('a', { staticClass: 'header-anchor', attrs: { href: '#_2-创建表' } }, [t._v('#')]), t._v(' 2. 创建表')]),
							t._v(' '),
							s('h3', { attrs: { id: '_2-1-start' } }, [s('a', { staticClass: 'header-anchor', attrs: { href: '#_2-1-start' } }, [t._v('#')]), t._v(' 2.1 start')]),
							t._v(' '),
							s('div', { staticClass: 'language-js extra-class' }, [
								s('pre', { pre: !0, attrs: { class: 'language-js' } }, [
									s('code', [
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// 设计表结构')]),
										t._v('\ntype Student struct '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										t._v('  \n  gorm'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										t._v('Model  \n  Name string  \n  Age int  \n'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										t._v('\ntype Teacher struct '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										t._v('\n  gorm'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										t._v('Model\n  Name string\n  Type string\n'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// 在连接数据库中创建表')]),
										t._v('\ndb'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('AutoMigrate')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('Person'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('Teacher'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\n'),
									]),
								]),
							]),
							s('p', [t._v('注意')]),
							t._v(' '),
							s('ol', [
								s('li', [t._v('GORM在存入数据库时，默认会将表名和表字段名转成'), s('code', [t._v('蛇形')]), t._v('，即'), s('code', [t._v('AaBbCcc -> aa_bb_ccc')])]),
								t._v(' '),
								s('li', [
									s('code', [t._v('gorm.Model')]),
									t._v('为默认的字段，包括字段'),
									s('code', [t._v('ID')]),
									t._v('、'),
									s('code', [t._v('CreatedAt')]),
									t._v('、'),
									s('code', [t._v('UpdatedAt')]),
									t._v('、'),
									s('code', [t._v('DeletedAt')]),
								]),
							]),
							t._v(' '),
							s('div', { staticClass: 'language-js extra-class' }, [
								s('pre', { pre: !0, attrs: { class: 'language-js' } }, [
									s('code', [
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// gorm.Model 的定义')]),
										t._v('\ntype Model struct '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										t._v('\n  '),
										s('span', { pre: !0, attrs: { class: 'token constant' } }, [t._v('ID')]),
										t._v('        uint           '),
										s('span', { pre: !0, attrs: { class: 'token template-string' } }, [
											s('span', { pre: !0, attrs: { class: 'token template-punctuation string' } }, [t._v('`')]),
											s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('gorm:"primaryKey"')]),
											s('span', { pre: !0, attrs: { class: 'token template-punctuation string' } }, [t._v('`')]),
										]),
										t._v('\n  CreatedAt time'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										t._v('Time\n  UpdatedAt time'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										t._v('Time\n  DeletedAt gorm'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										t._v('DeletedAt '),
										s('span', { pre: !0, attrs: { class: 'token template-string' } }, [
											s('span', { pre: !0, attrs: { class: 'token template-punctuation string' } }, [t._v('`')]),
											s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('gorm:"index"')]),
											s('span', { pre: !0, attrs: { class: 'token template-punctuation string' } }, [t._v('`')]),
										]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										t._v('\n'),
									]),
								]),
							]),
							s('h3', { attrs: { id: '_2-2-结构体嵌入' } }, [s('a', { staticClass: 'header-anchor', attrs: { href: '#_2-2-结构体嵌入' } }, [t._v('#')]), t._v(' 2.2 结构体嵌入')]),
							t._v(' '),
							s('p', [s('code', [t._v('gorm.Model')])]),
							t._v(' '),
							s('div', { staticClass: 'language-js extra-class' }, [
								s('pre', { pre: !0, attrs: { class: 'language-js' } }, [
									s('code', [
										t._v('type User struct '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										t._v('\n  gorm'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										t._v('Model\n  Name string\n'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// 等效于')]),
										t._v('\ntype User struct '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										t._v('\n  '),
										s('span', { pre: !0, attrs: { class: 'token constant' } }, [t._v('ID')]),
										t._v('        uint           '),
										s('span', { pre: !0, attrs: { class: 'token template-string' } }, [
											s('span', { pre: !0, attrs: { class: 'token template-punctuation string' } }, [t._v('`')]),
											s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('gorm:"primaryKey"')]),
											s('span', { pre: !0, attrs: { class: 'token template-punctuation string' } }, [t._v('`')]),
										]),
										t._v('\n  CreatedAt time'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										t._v('Time\n  UpdatedAt time'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										t._v('Time\n  DeletedAt gorm'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										t._v('DeletedAt '),
										s('span', { pre: !0, attrs: { class: 'token template-string' } }, [
											s('span', { pre: !0, attrs: { class: 'token template-punctuation string' } }, [t._v('`')]),
											s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('gorm:"index"')]),
											s('span', { pre: !0, attrs: { class: 'token template-punctuation string' } }, [t._v('`')]),
										]),
										t._v('\n  Name string\n'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										t._v('\n'),
									]),
								]),
							]),
							s('p', [t._v('其他结构体嵌入可通过'), s('code', [t._v('gorm:"embedded"')]), t._v('字段')]),
							t._v(' '),
							s('div', { staticClass: 'language-js extra-class' }, [
								s('pre', { pre: !0, attrs: { class: 'language-js' } }, [
									s('code', [
										t._v('type Author struct '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										t._v('\n  Name string\n'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										t._v('\ntype Blog struct '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										t._v('\n  Author Author '),
										s('span', { pre: !0, attrs: { class: 'token template-string' } }, [
											s('span', { pre: !0, attrs: { class: 'token template-punctuation string' } }, [t._v('`')]),
											s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('gorm:embedded')]),
											s('span', { pre: !0, attrs: { class: 'token template-punctuation string' } }, [t._v('`')]),
										]),
										t._v('\n  Id int\n'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										t._v('\n\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// 等价于')]),
										t._v('\ntype Blog struct '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										t._v('\n  Name string\n  Id int\n'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										t._v('\n'),
									]),
								]),
							]),
							s('p', [t._v('或者通过'), s('code', [t._v('embeddedPrefix')]), t._v('补充前缀')]),
							t._v(' '),
							s('div', { staticClass: 'language-js extra-class' }, [
								s('pre', { pre: !0, attrs: { class: 'language-js' } }, [
									s('code', [
										t._v('type Blog struct '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										t._v('\n  Author Author '),
										s('span', { pre: !0, attrs: { class: 'token template-string' } }, [
											s('span', { pre: !0, attrs: { class: 'token template-punctuation string' } }, [t._v('`')]),
											s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('gorm:embedded;embeddedPrefix:author_')]),
											s('span', { pre: !0, attrs: { class: 'token template-punctuation string' } }, [t._v('`')]),
										]),
										t._v('\n  Name string\n  Id int\n'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// 等价于')]),
										t._v('\ntype Blog struct '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										t._v('\n  AuthorName string\n  Name string\n  Id int\n'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										t._v('\n'),
									]),
								]),
							]),
							s('h2', { attrs: { id: '_3-crud操作' } }, [s('a', { staticClass: 'header-anchor', attrs: { href: '#_3-crud操作' } }, [t._v('#')]), t._v(' 3. CRUD操作')]),
							t._v(' '),
							s('p', [t._v('开始前先在库里创建表')]),
							t._v(' '),
							s('div', { staticClass: 'language-js extra-class' }, [
								s('pre', { pre: !0, attrs: { class: 'language-js' } }, [
									s('code', [
										t._v('type Person struct '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										t._v('\n  Name string\n  Age int\n'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										t._v('\ndb'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('AutoMigrate')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('Person'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\n'),
									]),
								]),
							]),
							s('h3', { attrs: { id: '_3-1-create' } }, [s('a', { staticClass: 'header-anchor', attrs: { href: '#_3-1-create' } }, [t._v('#')]), t._v(' 3.1 Create')]),
							t._v(' '),
							s('p', [s('strong', [t._v('创建单条')])]),
							t._v(' '),
							s('div', { staticClass: 'language-js extra-class' }, [
								s('pre', { pre: !0, attrs: { class: 'language-js' } }, [
									s('code', [
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('var')]),
										t._v(' user '),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('=')]),
										t._v(' Person'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										t._v('\n  '),
										s('span', { pre: !0, attrs: { class: 'token literal-property property' } }, [t._v('Name')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"noxone"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v('\n  '),
										s('span', { pre: !0, attrs: { class: 'token literal-property property' } }, [t._v('Age')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('18')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token literal-property property' } }, [t._v('res')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('=')]),
										t._v(' db'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Create')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('user'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\n\nuser'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token constant' } }, [t._v('ID')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// 主键')]),
										t._v('\nres'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										t._v('Error '),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// error')]),
										t._v('\nres'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										t._v('RowsAffected '),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// 插入记录条数')]),
										t._v('\n'),
									]),
								]),
							]),
							s('p', [s('strong', [t._v('创建多条')])]),
							t._v(' '),
							s('div', { staticClass: 'language-js extra-class' }, [
								s('pre', { pre: !0, attrs: { class: 'language-js' } }, [
									s('code', [
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('var')]),
										t._v(' users '),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('=')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('[')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(']')]),
										t._v('Person'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										t._v('\n  '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token literal-property property' } }, [t._v('Name')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"noxone1"')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v('\n  '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token literal-property property' } }, [t._v('Name')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"noxone2"')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v('\n  '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token literal-property property' } }, [t._v('Name')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"noxone3"')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										t._v('\n\n'),
										s('span', { pre: !0, attrs: { class: 'token literal-property property' } }, [t._v('res')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('=')]),
										t._v(' db'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Create')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('users'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('if')]),
										t._v(' res'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										t._v('Error '),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('!=')]),
										t._v(' nil '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										t._v('\n  '),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('return')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('for')]),
										t._v(' _'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token literal-property property' } }, [t._v('user')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('=')]),
										t._v(' range users '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										t._v('\n  user'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token constant' } }, [t._v('ID')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// 1 2 3')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										t._v('\n'),
									]),
								]),
							]),
							s('p', [s('strong', [t._v('使用Map创建')])]),
							t._v(' '),
							s('div', { staticClass: 'language-js extra-class' }, [
								s('pre', { pre: !0, attrs: { class: 'language-js' } }, [
									s('code', [
										t._v('db'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Model')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('Person'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Create')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										t._v('map'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('[')]),
										t._v('string'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(']')]),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('interface')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										t._v('\n  '),
										s('span', { pre: !0, attrs: { class: 'token string-property property' } }, [t._v('"Name"')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"noxone"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v('\n  '),
										s('span', { pre: !0, attrs: { class: 'token string-property property' } }, [t._v('"Age"')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('18')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\n'),
									]),
								]),
							]),
							s('h3', { attrs: { id: '_3-2-read' } }, [s('a', { staticClass: 'header-anchor', attrs: { href: '#_3-2-read' } }, [t._v('#')]), t._v(' 3.2 Read')]),
							t._v(' '),
							s('p', [s('strong', [t._v('查询之前 先创建接收容器')])]),
							t._v(' '),
							s('div', { staticClass: 'language-js extra-class' }, [
								s('pre', { pre: !0, attrs: { class: 'language-js' } }, [
									s('code', [
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('var')]),
										t._v(' user User\n'),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('var')]),
										t._v(' users '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('[')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(']')]),
										t._v('Users \n'),
									]),
								]),
							]),
							s('p', [s('strong', [t._v('查询主键')])]),
							t._v(' '),
							s('p', [t._v('GORM 提供了 '), s('code', [t._v('First')]), t._v('、'), s('code', [t._v('Take')]), t._v('、'), s('code', [t._v('Last')]), t._v(' 方法，以便从数据库中检索单个对象')]),
							t._v(' '),
							s('div', { staticClass: 'language-js extra-class' }, [
								s('pre', { pre: !0, attrs: { class: 'language-js' } }, [
									s('code', [
										t._v('db'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('First')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('user'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// SELECT * FROM persons ORDER BY id LIMIT 1')]),
										t._v('\ndb'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Take')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('user'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// SELECT * FROM persons LIMIT 1')]),
										t._v('\ndb'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Last')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('user'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// SELECT * FROM person ORDER BY id DESC LIMIT 1')]),
										t._v('\n\ndb'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('First')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('user'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('107')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// SELECT * FROM users WHERE id = 107')]),
										t._v('\n\ndb'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('First')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('user'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"id = ?"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"aaaabb"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v("// SELECT * FROM users WHERE id = 'aaaabb'")]),
										t._v('\n\ndb'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Find')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('users'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('[')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(']')]),
										t._v('int'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('1')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('2')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('3')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v(' \n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// SELECT * FROM users WHERE id IN (1,2,3)')]),
										t._v('\n'),
									]),
								]),
							]),
							s('p', [s('strong', [t._v('查询首项')])]),
							t._v(' '),
							s('div', { staticClass: 'language-js extra-class' }, [
								s('pre', { pre: !0, attrs: { class: 'language-js' } }, [
									s('code', [
										t._v('db'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Where')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"name = ?"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"noxone"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('First')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('user'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\ndb'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('First')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('user'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"name = ?"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"noxone"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// 简写')]),
										t._v('\n'),
									]),
								]),
							]),
							s('p', [s('strong', [t._v('查询所有项')])]),
							t._v(' '),
							s('div', { staticClass: 'language-js extra-class' }, [
								s('pre', { pre: !0, attrs: { class: 'language-js' } }, [
									s('code', [
										t._v('db'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Find')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('users'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"Age >= ?"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('12')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('  \ndb'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Where')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"Age >= ?"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('10')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Or')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"Age < ?"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('15')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Find')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('users'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\ndb'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Where')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"Age >= ? or Age < ?"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('10')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('15')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Find')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('users'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\n\ndb'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Find')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('users'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// 返回所有项')]),
										t._v('\n'),
									]),
								]),
							]),
							s('p', [s('strong', [t._v('String检索')])]),
							t._v(' '),
							s('div', { staticClass: 'language-js extra-class' }, [
								s('pre', { pre: !0, attrs: { class: 'language-js' } }, [
									s('code', [
										t._v('db'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Where')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"name = ?"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"noxone"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('First')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('user'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// 获取第一条匹配记录')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v("// SELECT * FROM users WHERE name = 'noxone' ORDER BY id LIMIT 1")]),
										t._v('\n\ndb'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Where')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"name <> ?"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"noxone"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Find')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('users'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// 获取全部匹配记录')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v("// SELECT * FROM users WHERE name <> 'noxone'")]),
										t._v('\n\ndb'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Where')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"id IN ?"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('[')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(']')]),
										t._v('uint'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('1')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('3')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('5')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Find')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('users'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// IN')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// SELECT * FROM users WHERE id IN (1, 2, 3)')]),
										t._v('\n\ndb'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Where')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"name = ? AND age < ?"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"noxone"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('17')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Find')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('users'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// AND')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v("// SELECT * FROM users WHERE name = 'noxone' AND age < 17")]),
										t._v('\n\ndb'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Where')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"age BETWEEN ? AND ?"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('18')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('22')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Find')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('users'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// BETWEEN')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// SELECT * FROM users WHERE age BETWEEN 18 AND 22')]),
										t._v('\n\ndb'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Where')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"name LIKE ?"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"%no%"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Find')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('users'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// LIKE')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v("// SELECT * FROM users WHERE name LIKE '%no%'")]),
										t._v('\n\ndb'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Where')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"updated_at > ?"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"2008-01-01 00:00:00"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Find')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('users'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// Time')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v("// SELECT * FROM users WHERE updated_at > '2008-01-01 00:00:00'")]),
										t._v('\n'),
									]),
								]),
							]),
							s('p', [s('strong', [t._v('Struct & Map检索')])]),
							t._v(' '),
							s('div', { staticClass: 'language-js extra-class' }, [
								s('pre', { pre: !0, attrs: { class: 'language-js' } }, [
									s('code', [
										t._v('db'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Where')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('User'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										s('span', { pre: !0, attrs: { class: 'token literal-property property' } }, [t._v('Name')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"noxone"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token literal-property property' } }, [t._v('Age')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('18')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('First')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('user'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v("// SELECT * FROM users WHERE name = 'noxone' AND age = 18 ORDER BY id LIMIT 1")]),
										t._v('\n\ndb'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Where')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										t._v('map'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('[')]),
										t._v('string'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(']')]),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('interface')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										s('span', { pre: !0, attrs: { class: 'token string-property property' } }, [t._v('"name"')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"noxone"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string-property property' } }, [t._v('"age"')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('18')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Find')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('users'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v("// SELECT * FROM users WHERE name = 'noxone' AND age = 18")]),
										t._v('\n\ndb'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Where')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('[')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(']')]),
										t._v('int64'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('1')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('3')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('5')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Find')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('users'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// SELECT * FROM users WHERE id IN (1, 3, 5)')]),
										t._v('\n\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// 注意！！！ 对于Struct的零值字段，不会被应用于sql查询，应使用map来代替')]),
										t._v('\ndb'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Where')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('User'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										s('span', { pre: !0, attrs: { class: 'token literal-property property' } }, [t._v('Name')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"noxone"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token literal-property property' } }, [t._v('Age')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('0')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Find')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('users'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v("// SELECT * FROM users WHERE name = 'noxone'")]),
										t._v('\n\ndb'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Where')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										t._v('map'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('[')]),
										t._v('string'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(']')]),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('interface')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										s('span', { pre: !0, attrs: { class: 'token string-property property' } }, [t._v('"name"')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"noxone"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string-property property' } }, [t._v('"age"')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('0')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Find')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('users'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v("// SELECT * FROM users WHERE name = 'noxone' AND age = 0")]),
										t._v('\n'),
									]),
								]),
							]),
							s('p', [s('strong', [t._v('内联检索')])]),
							t._v(' '),
							s('p', [t._v('属于优雅写法')]),
							t._v(' '),
							s('div', { staticClass: 'language-js extra-class' }, [
								s('pre', { pre: !0, attrs: { class: 'language-js' } }, [
									s('code', [
										t._v('db'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Find')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('users'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"name = ?"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"noxone"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\ndb'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Find')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('users'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"name = ? AND age > ?"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"noxone"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('18')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\ndb'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Find')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('users'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' User'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										s('span', { pre: !0, attrs: { class: 'token literal-property property' } }, [t._v('Name')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"noxone"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\ndb'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Find')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('users'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' map'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('[')]),
										t._v('string'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(']')]),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('interface')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										s('span', { pre: !0, attrs: { class: 'token string-property property' } }, [t._v('"name"')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"noxone"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\n'),
									]),
								]),
							]),
							s('p', [s('strong', [t._v('NOT')])]),
							t._v(' '),
							s('div', { staticClass: 'language-js extra-class' }, [
								s('pre', { pre: !0, attrs: { class: 'language-js' } }, [
									s('code', [
										t._v('db'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token constant' } }, [t._v('NOT')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"name = ?"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"noxone"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Find')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('users'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// SELECT * FROM users WHERE NOT name = "noxone"')]),
										t._v('\n\ndb'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token constant' } }, [t._v('NOT')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										t._v('User'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										s('span', { pre: !0, attrs: { class: 'token literal-property property' } }, [t._v('Name')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"noxone"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token literal-property property' } }, [t._v('Age')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('18')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Find')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('users'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// SELECT * FROM users WHERE name <> "noxone" AND age <> 18')]),
										t._v('\n\ndb'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token constant' } }, [t._v('NOT')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										t._v('map'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('[')]),
										t._v('string'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(']')]),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('interface')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										s('span', { pre: !0, attrs: { class: 'token string-property property' } }, [t._v('"age"')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('[')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(']')]),
										t._v('int'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('17')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('18')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('19')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// SELECT * FROM users WHERE age NOT IN (17, 18, 19)')]),
										t._v('\n'),
									]),
								]),
							]),
							s('p', [s('strong', [t._v('Limit & Offset')])]),
							t._v(' '),
							s('div', { staticClass: 'language-js extra-class' }, [
								s('pre', { pre: !0, attrs: { class: 'language-js' } }, [
									s('code', [
										t._v('db'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Limit')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('3')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Find')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('users'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// SELECT * FROM users LIMIT 3')]),
										t._v('\n\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// 通过 -1 消除 Limit 条件')]),
										t._v('\ndb'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Limit')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('10')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Find')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('users1'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Limit')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('-')]),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('1')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Find')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('users2'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// SELECT * FROM users LIMIT 10; (users1)')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// SELECT * FROM users; (users2)')]),
										t._v('\n\ndb'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Offset')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('3')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Find')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('users'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// SELECT * FROM users OFFSET 3')]),
										t._v('\n\ndb'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Limit')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('10')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Offset')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('5')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Find')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('users'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// SELECT * FROM users OFFSET 5 LIMIT 10')]),
										t._v('\n\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// 通过 -1 消除 Offset 条件')]),
										t._v('\ndb'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Offset')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('10')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Find')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('users1'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Offset')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('-')]),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('1')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Find')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('users2'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// SELECT * FROM users OFFSET 10; (users1)')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// SELECT * FROM users; (users2)')]),
										t._v('\n'),
									]),
								]),
							]),
							s('h3', { attrs: { id: '_3-3-update' } }, [s('a', { staticClass: 'header-anchor', attrs: { href: '#_3-3-update' } }, [t._v('#')]), t._v(' 3.3 Update')]),
							t._v(' '),
							s('p', [s('strong', [t._v('修改之前 先查询')])]),
							t._v(' '),
							s('div', { staticClass: 'language-js extra-class' }, [
								s('pre', { pre: !0, attrs: { class: 'language-js' } }, [
									s('code', [
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('var')]),
										t._v(' user User \ndb'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('First')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('user'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('7')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\n'),
									]),
								]),
							]),
							s('p', [s('strong', [t._v('更新所有字段')])]),
							t._v(' '),
							s('div', { staticClass: 'language-js extra-class' }, [
								s('pre', { pre: !0, attrs: { class: 'language-js' } }, [
									s('code', [
										t._v('user'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										t._v('Name '),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('=')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"noxone"')]),
										t._v('\nuser'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										t._v('Age '),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('=')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('22')]),
										t._v('\ndb'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Save')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('user'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// UPDATE users SET name="noxone", age=22 updated_at = \'2023-5-12 17:00:00\' WHERE id=7')]),
										t._v('\n'),
									]),
								]),
							]),
							s('p', [s('strong', [t._v('更新单个字段')])]),
							t._v(' '),
							s('div', { staticClass: 'language-js extra-class' }, [
								s('pre', { pre: !0, attrs: { class: 'language-js' } }, [
									s('code', [
										t._v('db'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Model')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('user'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Update')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"name"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"noxone"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// UPDATE users SET name="noxone", updated_at = \'2023-5-12 17:00:00\' WHERE id=7')]),
										t._v('\n'),
									]),
								]),
							]),
							s('p', [s('strong', [t._v('更新多个字段')])]),
							t._v(' '),
							s('div', { staticClass: 'language-js extra-class' }, [
								s('pre', { pre: !0, attrs: { class: 'language-js' } }, [
									s('code', [
										t._v('db'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Model')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('user'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Updates')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										t._v('User'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										s('span', { pre: !0, attrs: { class: 'token literal-property property' } }, [t._v('Name')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"noxone"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token literal-property property' } }, [t._v('Age')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('22')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\ndb'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Model')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('user'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Updates')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										t._v('map'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('[')]),
										t._v('string'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(']')]),
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('interface')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										s('span', { pre: !0, attrs: { class: 'token string-property property' } }, [t._v('"name"')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"noxone"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string-property property' } }, [t._v('"age"')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('22')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// UPDATE users SET name="noxone", age=22 updated_at = \'2023-5-12 17:00:00\' WHERE id=7')]),
										t._v('\n'),
									]),
								]),
							]),
							s('p', [s('strong', [t._v('更新选定字段')])]),
							t._v(' '),
							s('div', { staticClass: 'language-js extra-class' }, [
								s('pre', { pre: !0, attrs: { class: 'language-js' } }, [
									s('code', [
										t._v('db'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Model')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('user'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Select')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"name"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Updates')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										t._v('User'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										s('span', { pre: !0, attrs: { class: 'token literal-property property' } }, [t._v('Name')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"noxone"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token literal-property property' } }, [t._v('Age')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('22')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// UPDATE users SET name="noxone", updated_at = \'2023-5-12 17:00:00\' WHERE id=7')]),
										t._v('\n\ndb'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Model')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('user'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Omit')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"name"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Updates')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										t._v('User'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										s('span', { pre: !0, attrs: { class: 'token literal-property property' } }, [t._v('Name')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"noxone"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token literal-property property' } }, [t._v('Age')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('22')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v("// UPDATE users SET age=22 updated_at = '2023-5-12 17:00:00' WHERE id=7")]),
										t._v('\n\ndb'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Model')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('user'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Select')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"name"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"age"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Updates')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										t._v('User'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										s('span', { pre: !0, attrs: { class: 'token literal-property property' } }, [t._v('Name')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"noxone"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token literal-property property' } }, [t._v('Age')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('22')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token literal-property property' } }, [t._v('IsHandsome')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token boolean' } }, [t._v('true')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// UPDATE users SET name="noxone", age=22 updated_at = \'2023-5-12 17:00:00\' WHERE id=7')]),
										t._v('\n'),
									]),
								]),
							]),
							s('h3', { attrs: { id: '_3-4-delete' } }, [s('a', { staticClass: 'header-anchor', attrs: { href: '#_3-4-delete' } }, [t._v('#')]), t._v(' 3.4 Delete')]),
							t._v(' '),
							s('div', { staticClass: 'language-js extra-class' }, [
								s('pre', { pre: !0, attrs: { class: 'language-js' } }, [
									s('code', [
										t._v('db'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Where')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"name = ?"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"noxone"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('First')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('Person'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Delete')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('Person'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// 软删除')]),
										t._v('\ndb'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Where')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"age in (?)"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('[')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(']')]),
										t._v('int'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('10')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('15')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Unscoped')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Delete')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('Person'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// 硬删除')]),
										t._v('\n'),
									]),
								]),
							]),
							s('h3', { attrs: { id: '_3-5-rud-by-id' } }, [s('a', { staticClass: 'header-anchor', attrs: { href: '#_3-5-rud-by-id' } }, [t._v('#')]), t._v(' 3.5 RUD By Id')]),
							t._v(' '),
							s('div', { staticClass: 'language-js extra-class' }, [
								s('pre', { pre: !0, attrs: { class: 'language-js' } }, [
									s('code', [
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('var')]),
										t._v(' user User\n\n'),
										s('span', { pre: !0, attrs: { class: 'token literal-property property' } }, [t._v('tx')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('=')]),
										t._v(' db'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('First')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('user'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('107')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// read  ')]),
										t._v('\n\ntx'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Updates')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										t._v('User'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// update  ')]),
										t._v('\n  '),
										s('span', { pre: !0, attrs: { class: 'token literal-property property' } }, [t._v('Name')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"sd"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v('  \n  '),
										s('span', { pre: !0, attrs: { class: 'token literal-property property' } }, [t._v('Age')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v(':')]),
										t._v('  '),
										s('span', { pre: !0, attrs: { class: 'token number' } }, [t._v('0')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v('  \n'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('  \n\ntx'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Delete')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('User'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// delete (soft)  ')]),
										t._v('\ntx'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Unscoped')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Delete')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('User'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('{')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('}')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// delete (hard)')]),
										t._v('\n'),
									]),
								]),
							]),
							s('h2', { attrs: { id: '_4-关系表' } }, [s('a', { staticClass: 'header-anchor', attrs: { href: '#_4-关系表' } }, [t._v('#')]), t._v(' 4. 关系表')]),
							t._v(' '),
							s('h3', { attrs: { id: '_4-1-belongs-to' } }, [s('a', { staticClass: 'header-anchor', attrs: { href: '#_4-1-belongs-to' } }, [t._v('#')]), t._v(' 4.1 Belongs To')]),
							t._v(' '),
							s('p', [s('strong', [s('code', [t._v('belongs to')]), t._v('将从属者的主字段+ID作为外键值，从而建立从属关系')])]),
							t._v(' '),
							s('div', { staticClass: 'language-golang extra-class' }, [
								s('pre', { pre: !0, attrs: { class: 'language-text' } }, [
									s('code', [
										t._v(
											'// 当user分配给某个company时，会自动把关联company的ID作为外键值保存到CompanyID字段，从而建立一对一的从属连接\ntype User struct {  \n  gorm.Model  \n  Name string  \n  CompanyID int  \n  Company Company  \n}  \ntype Company struct {  \n  Id int  \n  Name string  \n}  \n',
										),
									]),
								]),
							]),
							s('p', [s('strong', [t._v('重写外键')])]),
							t._v(' '),
							s('div', { staticClass: 'language-golang extra-class' }, [
								s('pre', { pre: !0, attrs: { class: 'language-text' } }, [
									s('code', [
										t._v(
											'// 使用 CompanyRefer 作为外键  \ntype User struct {  \n  gorm.Model  \n  Name string  \n  CompanyRefer string  \n  Company Company `gorm:"foreignKey:CompanyRefer"`  \n}  \ntype Company struct {  \n  Id int  \n  Name string  \n}\n',
										),
									]),
								]),
							]),
							s('p', [s('strong', [t._v('重写引用')])]),
							t._v(' '),
							s('div', { staticClass: 'language-golang extra-class' }, [
								s('pre', { pre: !0, attrs: { class: 'language-text' } }, [
									s('code', [
										t._v(
											'// 使用 Code 作为引用，这时会将关联company的Code作为外键值保存到CompanyID字段\ntype User struct {  \n  gorm.Model  \n  Name string  \n  CompanyID string  // CompanyID作为外键\n  Company Company `gorm:"references:Code"`  \n}  \ntype Company struct {  \n  Id int  \n  Code string  \n  Name string  \n}\n',
										),
									]),
								]),
							]),
							s('h3', { attrs: { id: '_4-2-has-one' } }, [s('a', { staticClass: 'header-anchor', attrs: { href: '#_4-2-has-one' } }, [t._v('#')]), t._v(' 4.2 Has one')]),
							t._v(' '),
							s('p', [s('strong', [s('code', [t._v('has one')]), t._v('将关联Model的实例作为外键，从而建立一对一的关联')])]),
							t._v(' '),
							s('div', { staticClass: 'language-golang extra-class' }, [
								s('pre', { pre: !0, attrs: { class: 'language-text' } }, [
									s('code', [t._v('type User struct {  \n  gorm.Model  \n  IdCard IdCard  // IdCard作为外键  \n}  \ntype IdCard struct {  \n  gorm.Model  \n  Number string  \n  UserID uint  \n}\n')]),
								]),
							]),
							s('h3', { attrs: { id: '_4-3-has-many' } }, [s('a', { staticClass: 'header-anchor', attrs: { href: '#_4-3-has-many' } }, [t._v('#')]), t._v(' 4.3 Has Many')]),
							t._v(' '),
							s('p', [s('strong', [s('code', [t._v('has many')]), t._v('将关联Model的多个实例作为外键，从而建立一对多的关联')])]),
							t._v(' '),
							s('div', { staticClass: 'language-golang extra-class' }, [
								s('pre', { pre: !0, attrs: { class: 'language-text' } }, [
									s('code', [
										t._v('type js struct {  \n  gorm.Model  \n  IdCards []IdCard  // []IdCard作为外键\n}  \ntype IdCard struct {  \n  gorm.Model  \n  Number string  \n  UserID uint  \n}\n'),
									]),
								]),
							]),
							s('h3', { attrs: { id: '_4-4-many-to-many' } }, [s('a', { staticClass: 'header-anchor', attrs: { href: '#_4-4-many-to-many' } }, [t._v('#')]), t._v(' 4.4 Many To Many')]),
							t._v(' '),
							s('p', [s('strong', [s('code', [t._v('many to many')]), t._v('会创建两个Model之间的连接表')])]),
							t._v(' '),
							s('div', { staticClass: 'language-golang extra-class' }, [
								s('pre', { pre: !0, attrs: { class: 'language-text' } }, [
									s('code', [
										t._v(
											'type User struct {  \n  gorm.Model  \n  Courses []*Course `gorm:"many2many:user_courses"`  \n}  \ntype Course struct {  \n  gorm.Model  \n  Name string  \n  Users []*User `gorm:"many2many:user_languages"`\n}\n',
										),
									]),
								]),
							]),
							s('p', [
								t._v('这里会在'),
								s('code', [t._v('user')]),
								t._v('和'),
								s('code', [t._v('course')]),
								t._v('表之间创建一个中间连接表'),
								s('code', [t._v('user_courses')]),
								t._v('，从而可以得到user和course之间的多对多映射，即一个user会关联多个course，一个course也会关联多个user'),
							]),
							t._v(' '),
							s('h3', { attrs: { id: '_4-5-preload' } }, [s('a', { staticClass: 'header-anchor', attrs: { href: '#_4-5-preload' } }, [t._v('#')]), t._v(' 4.5 Preload')]),
							t._v(' '),
							s('p', [t._v('先建立全部类型的表')]),
							t._v(' '),
							s('div', { staticClass: 'language-golang extra-class' }, [
								s('pre', { pre: !0, attrs: { class: 'language-text' } }, [
									s('code', [
										t._v(
											'type Person struct {  \n  gorm.Model  \n  IdCard IdCard // has one 一对一  \n  CreditCards []CreditCard // has many 一对多  \n  FamilyID string  \n  Family Family // belongs to 从属  \n  Clubs []Club `gorm:"many2many:user_club"`  // many to many 多对多\n}  \n  \ntype IdCard struct {  // 身份证\n  gorm.Model  \n  Number string  \n}  \ntype CreditCard struct {  // 银行卡\n  gorm.Model  \n  Type string  \n  Number string  \n}  \ntype Family struct {  // 家庭\n  gorm.Model  \n  Members []Person  \n}  \ntype Club struct {  // 俱乐部\n  gorm.Model  \n  Type string  \n  Members []Person  \n}\n',
										),
									]),
								]),
							]),
							s('p', [t._v('使用'), s('code', [t._v('Preload')]), t._v('可以在查询时加载关联表数据')]),
							t._v(' '),
							s('div', { staticClass: 'language-js extra-class' }, [
								s('pre', { pre: !0, attrs: { class: 'language-js' } }, [
									s('code', [
										s('span', { pre: !0, attrs: { class: 'token keyword' } }, [t._v('var')]),
										t._v(' persons '),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('[')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(']')]),
										t._v('Person\ndb'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Preload')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"IdCard"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"CreditCards"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"Family"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(',')]),
										t._v(' '),
										s('span', { pre: !0, attrs: { class: 'token string' } }, [t._v('"Clubs"')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('.')]),
										s('span', { pre: !0, attrs: { class: 'token function' } }, [t._v('Find')]),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v('(')]),
										s('span', { pre: !0, attrs: { class: 'token operator' } }, [t._v('&')]),
										t._v('persons'),
										s('span', { pre: !0, attrs: { class: 'token punctuation' } }, [t._v(')')]),
										t._v('  \n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// SELECT * FROM persons  ')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// SELECT * FROM idcards WHERE person_id IN (1,2,3,4,5) 一对一  ')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// SELECT * FROM credit_cards WHERE person_id IN (1,2,3,4,5) 一对多  ')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// SELECT * FROM familys WHERE id IN (1,2) 从属  ')]),
										t._v('\n'),
										s('span', { pre: !0, attrs: { class: 'token comment' } }, [t._v('// SELECT * FROM clubs WHERE id IN (1,2) 多对多')]),
										t._v('\n'),
									]),
								]),
							]),
						])
					},
					[],
					!1,
					null,
					null,
					null,
				)
			s.default = e.exports
		},
	},
])
